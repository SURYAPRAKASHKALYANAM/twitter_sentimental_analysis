{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "076e8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80aef45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('mexico_earthquake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950d3258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @FCBarcelona: Our solidarity with the victi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mexico earthquake: Many children killed at pri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Obamaâ€™s Response To The Earthquake In #Mexic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @AmichaiStein1: #BREAKING: Israel search &amp;a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @AmichaiStein1: #BREAKING: Israel search &amp;a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>Carlos santana donates $100k to mexico earthqu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>Seth troxler donates 10k to earthquake relief ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>Entercom/San Francisco Stations Raise Funds Fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>Mexico Earthquakes | International Medical Cor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>Napa school employee Valentin Fuentes Villanue...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Label\n",
       "0     RT @FCBarcelona: Our solidarity with the victi...      0\n",
       "1     Mexico earthquake: Many children killed at pri...      1\n",
       "2     Obamaâ€™s Response To The Earthquake In #Mexic...      0\n",
       "3     RT @AmichaiStein1: #BREAKING: Israel search &a...      1\n",
       "4     RT @AmichaiStein1: #BREAKING: Israel search &a...      1\n",
       "...                                                 ...    ...\n",
       "1375  Carlos santana donates $100k to mexico earthqu...      1\n",
       "1376  Seth troxler donates 10k to earthquake relief ...      1\n",
       "1377  Entercom/San Francisco Stations Raise Funds Fo...      1\n",
       "1378  Mexico Earthquakes | International Medical Cor...      1\n",
       "1379  Napa school employee Valentin Fuentes Villanue...      1\n",
       "\n",
       "[1380 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e764e832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet    0\n",
       "Label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694e5dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(x):\n",
    "    return x.lower()\n",
    "df['Tweet']=df['Tweet'].apply(lower)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "657abc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @fcbarcelona: our solidarity with the victi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mexico earthquake: many children killed at pri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obamaâ€™s response to the earthquake in #mexic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @amichaistein1: #breaking: israel search &amp;a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @amichaistein1: #breaking: israel search &amp;a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>carlos santana donates $100k to mexico earthqu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>seth troxler donates 10k to earthquake relief ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>entercom/san francisco stations raise funds fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>mexico earthquakes | international medical cor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>napa school employee valentin fuentes villanue...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Label\n",
       "0     rt @fcbarcelona: our solidarity with the victi...      0\n",
       "1     mexico earthquake: many children killed at pri...      1\n",
       "2     obamaâ€™s response to the earthquake in #mexic...      0\n",
       "3     rt @amichaistein1: #breaking: israel search &a...      1\n",
       "4     rt @amichaistein1: #breaking: israel search &a...      1\n",
       "...                                                 ...    ...\n",
       "1375  carlos santana donates $100k to mexico earthqu...      1\n",
       "1376  seth troxler donates 10k to earthquake relief ...      1\n",
       "1377  entercom/san francisco stations raise funds fo...      1\n",
       "1378  mexico earthquakes | international medical cor...      1\n",
       "1379  napa school employee valentin fuentes villanue...      1\n",
       "\n",
       "[1380 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6594162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emot.emo_unicode import UNICODE_EMOJI\n",
    "# Function for converting emojis into word\n",
    "def convert_emojis(text):\n",
    "    for emot in UNICODE_EMOJI:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMOJI[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "    return text\n",
    "df['Tweet']=df['Tweet'].apply(convert_emojis)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e689810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @fcbarcelona: our solidarity with the victi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mexico earthquake: many children killed at pri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obamaâ€trade_marks response to the earthquake ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt @amichaistein1: #breaking: israel search &amp;a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @amichaistein1: #breaking: israel search &amp;a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>carlos santana donates $100k to mexico earthqu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>seth troxler donates 10k to earthquake relief ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>entercom/san francisco stations raise funds fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>mexico earthquakes | international medical cor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>napa school employee valentin fuentes villanue...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Label\n",
       "0     rt @fcbarcelona: our solidarity with the victi...      0\n",
       "1     mexico earthquake: many children killed at pri...      1\n",
       "2     obamaâ€trade_marks response to the earthquake ...      0\n",
       "3     rt @amichaistein1: #breaking: israel search &a...      1\n",
       "4     rt @amichaistein1: #breaking: israel search &a...      1\n",
       "...                                                 ...    ...\n",
       "1375  carlos santana donates $100k to mexico earthqu...      1\n",
       "1376  seth troxler donates 10k to earthquake relief ...      1\n",
       "1377  entercom/san francisco stations raise funds fo...      1\n",
       "1378  mexico earthquakes | international medical cor...      1\n",
       "1379  napa school employee valentin fuentes villanue...      1\n",
       "\n",
       "[1380 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dc38a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def tokenize(x):\n",
    "    return word_tokenize(x)\n",
    "df['Tweet']=df['Tweet'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ad2f7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[rt, @, fcbarcelona, :, our, solidarity, with,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mexico, earthquake, :, many, children, killed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[obamaâ€trade_marks, response, to, the, earthq...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[rt, @, amichaistein1, :, #, breaking, :, isra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[rt, @, amichaistein1, :, #, breaking, :, isra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>[carlos, santana, donates, $, 100k, to, mexico...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>[seth, troxler, donates, 10k, to, earthquake, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>[entercom/san, francisco, stations, raise, fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>[mexico, earthquakes, |, international, medica...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>[napa, school, employee, valentin, fuentes, vi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Label\n",
       "0     [rt, @, fcbarcelona, :, our, solidarity, with,...      0\n",
       "1     [mexico, earthquake, :, many, children, killed...      1\n",
       "2     [obamaâ€trade_marks, response, to, the, earthq...      0\n",
       "3     [rt, @, amichaistein1, :, #, breaking, :, isra...      1\n",
       "4     [rt, @, amichaistein1, :, #, breaking, :, isra...      1\n",
       "...                                                 ...    ...\n",
       "1375  [carlos, santana, donates, $, 100k, to, mexico...      1\n",
       "1376  [seth, troxler, donates, 10k, to, earthquake, ...      1\n",
       "1377  [entercom/san, francisco, stations, raise, fun...      1\n",
       "1378  [mexico, earthquakes, |, international, medica...      1\n",
       "1379  [napa, school, employee, valentin, fuentes, vi...      1\n",
       "\n",
       "[1380 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f05ce8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(x):\n",
    "    import string\n",
    "    punct_tag=set(string.punctuation)\n",
    "    t=[i for i in x if i not in punct_tag]\n",
    "    return t\n",
    "      \n",
    "df['Tweet']=df['Tweet'].apply(remove_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def2ba07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[rt, fcbarcelona, our, solidarity, with, the, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mexico, earthquake, many, children, killed, a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[obamaâ€trade_marks, response, to, the, earthq...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[rt, amichaistein1, breaking, israel, search, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[rt, amichaistein1, breaking, israel, search, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>[carlos, santana, donates, 100k, to, mexico, e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>[seth, troxler, donates, 10k, to, earthquake, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>[entercom/san, francisco, stations, raise, fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>[mexico, earthquakes, international, medical, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>[napa, school, employee, valentin, fuentes, vi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Label\n",
       "0     [rt, fcbarcelona, our, solidarity, with, the, ...      0\n",
       "1     [mexico, earthquake, many, children, killed, a...      1\n",
       "2     [obamaâ€trade_marks, response, to, the, earthq...      0\n",
       "3     [rt, amichaistein1, breaking, israel, search, ...      1\n",
       "4     [rt, amichaistein1, breaking, israel, search, ...      1\n",
       "...                                                 ...    ...\n",
       "1375  [carlos, santana, donates, 100k, to, mexico, e...      1\n",
       "1376  [seth, troxler, donates, 10k, to, earthquake, ...      1\n",
       "1377  [entercom/san, francisco, stations, raise, fun...      1\n",
       "1378  [mexico, earthquakes, international, medical, ...      1\n",
       "1379  [napa, school, employee, valentin, fuentes, vi...      1\n",
       "\n",
       "[1380 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ccf9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whites(x):\n",
    "    w={' '}\n",
    "    x=[i for i in x if i not in w]\n",
    "    return x\n",
    "df['Tweet']=df['Tweet'].apply(whites)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61c13528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[rt, fcbarcelona, our, solidarity, with, the, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mexico, earthquake, many, children, killed, a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[obamaâ€trade_marks, response, to, the, earthq...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[rt, amichaistein1, breaking, israel, search, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[rt, amichaistein1, breaking, israel, search, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>[carlos, santana, donates, 100k, to, mexico, e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>[seth, troxler, donates, 10k, to, earthquake, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>[entercom/san, francisco, stations, raise, fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>[mexico, earthquakes, international, medical, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>[napa, school, employee, valentin, fuentes, vi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Label\n",
       "0     [rt, fcbarcelona, our, solidarity, with, the, ...      0\n",
       "1     [mexico, earthquake, many, children, killed, a...      1\n",
       "2     [obamaâ€trade_marks, response, to, the, earthq...      0\n",
       "3     [rt, amichaistein1, breaking, israel, search, ...      1\n",
       "4     [rt, amichaistein1, breaking, israel, search, ...      1\n",
       "...                                                 ...    ...\n",
       "1375  [carlos, santana, donates, 100k, to, mexico, e...      1\n",
       "1376  [seth, troxler, donates, 10k, to, earthquake, ...      1\n",
       "1377  [entercom/san, francisco, stations, raise, fun...      1\n",
       "1378  [mexico, earthquakes, international, medical, ...      1\n",
       "1379  [napa, school, employee, valentin, fuentes, vi...      1\n",
       "\n",
       "[1380 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8896c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "def re_stop(x):\n",
    "    nltk_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    return [ token for token in x if token not in nltk_stopwords]\n",
    "df['Tweet']=df['Tweet'].apply(re_stop)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0f6057e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[rt, fcbarcelona, solidarity, victims, earthqu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mexico, earthquake, many, children, killed, p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[obamaâ€trade_marks, response, earthquake, mex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[rt, amichaistein1, breaking, israel, search, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[rt, amichaistein1, breaking, israel, search, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>[carlos, santana, donates, 100k, mexico, earth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>[seth, troxler, donates, 10k, earthquake, reli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>[entercom/san, francisco, stations, raise, fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>[mexico, earthquakes, international, medical, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>[napa, school, employee, valentin, fuentes, vi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Label\n",
       "0     [rt, fcbarcelona, solidarity, victims, earthqu...      0\n",
       "1     [mexico, earthquake, many, children, killed, p...      1\n",
       "2     [obamaâ€trade_marks, response, earthquake, mex...      0\n",
       "3     [rt, amichaistein1, breaking, israel, search, ...      1\n",
       "4     [rt, amichaistein1, breaking, israel, search, ...      1\n",
       "...                                                 ...    ...\n",
       "1375  [carlos, santana, donates, 100k, mexico, earth...      1\n",
       "1376  [seth, troxler, donates, 10k, earthquake, reli...      1\n",
       "1377  [entercom/san, francisco, stations, raise, fun...      1\n",
       "1378  [mexico, earthquakes, international, medical, ...      1\n",
       "1379  [napa, school, employee, valentin, fuentes, vi...      1\n",
       "\n",
       "[1380 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8102ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "def lemm(x):\n",
    "    l=[]\n",
    "    for i in x:\n",
    "        l.append(WordNetLemmatizer().lemmatize(i))\n",
    "    return l    \n",
    "df['Tweet']=df['Tweet'].apply(lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db7d544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "def stemm(x):\n",
    "    l=[]\n",
    "    for i in x:\n",
    "        l.append(PorterStemmer().stem(i))\n",
    "    return l    \n",
    "df['Tweet']=df['Tweet'].apply(stemm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52e5fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine(x):\n",
    "#     return ' '.join(x)\n",
    "# df['Tweet']=df['Tweet'].apply(combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fede965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[rt, fcbarcelona, solidar, victim, earthquak, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mexico, earthquak, mani, child, kill, primari...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[obamaâ€trade_mark, respons, earthquak, mexico...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[rt, amichaistein1, break, israel, search, amp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[rt, amichaistein1, break, israel, search, amp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>[carlo, santana, donat, 100k, mexico, earthqua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>[seth, troxler, donat, 10k, earthquak, relief,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>[entercom/san, francisco, station, rais, fund,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>[mexico, earthquak, intern, medic, corp, http,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>[napa, school, employe, valentin, fuent, villa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1380 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Label\n",
       "0     [rt, fcbarcelona, solidar, victim, earthquak, ...      0\n",
       "1     [mexico, earthquak, mani, child, kill, primari...      1\n",
       "2     [obamaâ€trade_mark, respons, earthquak, mexico...      0\n",
       "3     [rt, amichaistein1, break, israel, search, amp...      1\n",
       "4     [rt, amichaistein1, break, israel, search, amp...      1\n",
       "...                                                 ...    ...\n",
       "1375  [carlo, santana, donat, 100k, mexico, earthqua...      1\n",
       "1376  [seth, troxler, donat, 10k, earthquak, relief,...      1\n",
       "1377  [entercom/san, francisco, station, rais, fund,...      1\n",
       "1378  [mexico, earthquak, intern, medic, corp, http,...      1\n",
       "1379  [napa, school, employe, valentin, fuent, villa...      1\n",
       "\n",
       "[1380 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ac1af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "X=df['Tweet']\n",
    "glove={}\n",
    "total_vocabulary = set(word for text in X for word in text)\n",
    "with open(r\"D:\\deployment\\abc\\proj\\media\\glove.twitter.27B.100.txt\", \"rb\") as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode(\"utf-8\")\n",
    "        if word in total_vocabulary:\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove[word] = vector\n",
    "\n",
    "class W2vVectorizer(object):\n",
    "    def __init__(self, w2v):\n",
    "        self.w2v = w2v\n",
    "        if len(w2v) == 0:\n",
    "            self.dimensions = 0\n",
    "        else:\n",
    "            self.dimensions = len(w2v[next(iter(glove))])\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([np.mean([self.w2v[w] for w in words if w in self.w2v] or [np.zeros(self.dimensions)],axis=0,) for words in X])\n",
    "\n",
    "vectorizer = W2vVectorizer(glove)\n",
    "X_glove = vectorizer.transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_glove,df['Label'], test_size=0.2)\n",
    "X_train_vtc = X_train\n",
    "X_test_vtc = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bce14834",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,df['Label'], test_size=0.2,random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "267371a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.25      0.35        71\n",
      "           1       0.78      0.94      0.85       205\n",
      "\n",
      "    accuracy                           0.76       276\n",
      "   macro avg       0.68      0.60      0.60       276\n",
      "weighted avg       0.73      0.76      0.72       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_l=LogisticRegression().fit(X_train,y_train)\n",
    "y_pred=model_l.predict(X_test)\n",
    "score=classification_report(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c5d8735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.11      0.20        71\n",
      "           1       0.76      1.00      0.87       205\n",
      "\n",
      "    accuracy                           0.77       276\n",
      "   macro avg       0.88      0.56      0.53       276\n",
      "weighted avg       0.83      0.77      0.70       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "rf_kn =SVC()\n",
    "rf_model_kn = rf_kn.fit(X_train, y_train)\n",
    "y_pred = rf_model_kn.predict(X_test)\n",
    "score1=classification_report(y_test, y_pred)\n",
    "print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d4f077a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.42      0.44        71\n",
      "           1       0.81      0.83      0.82       205\n",
      "\n",
      "    accuracy                           0.72       276\n",
      "   macro avg       0.63      0.63      0.63       276\n",
      "weighted avg       0.72      0.72      0.72       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "rf_kn = DecisionTreeClassifier()\n",
    "rf_model_kn = rf_kn.fit(X_train, y_train)\n",
    "y_pred = rf_model_kn.predict(X_test)\n",
    "score1=classification_report(y_test, y_pred)\n",
    "print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2349629c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.23      0.36        71\n",
      "           1       0.79      1.00      0.88       205\n",
      "\n",
      "    accuracy                           0.80       276\n",
      "   macro avg       0.86      0.61      0.62       276\n",
      "weighted avg       0.83      0.80      0.75       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_kn = RandomForestClassifier()\n",
    "rf_model_kn = rf_kn.fit(X_train, y_train)\n",
    "y_pred = rf_model_kn.predict(X_test)\n",
    "score1=classification_report(y_test, y_pred)\n",
    "print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caf50097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.17      0.27        71\n",
      "           1       0.77      0.98      0.86       205\n",
      "\n",
      "    accuracy                           0.77       276\n",
      "   macro avg       0.74      0.57      0.57       276\n",
      "weighted avg       0.76      0.77      0.71       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "rf_kn = KNeighborsClassifier()\n",
    "rf_model_kn = rf_kn.fit(X_train, y_train)\n",
    "y_pred = rf_model_kn.predict(X_test)\n",
    "score1=classification_report(y_test, y_pred)\n",
    "print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bc79338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.42      0.43        71\n",
      "           1       0.80      0.81      0.81       205\n",
      "\n",
      "    accuracy                           0.71       276\n",
      "   macro avg       0.62      0.62      0.62       276\n",
      "weighted avg       0.71      0.71      0.71       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "score1=classification_report(y_test, y_pred)\n",
    "print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be8fc181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.28      0.39        71\n",
      "           1       0.79      0.94      0.86       205\n",
      "\n",
      "    accuracy                           0.77       276\n",
      "   macro avg       0.71      0.61      0.62       276\n",
      "weighted avg       0.75      0.77      0.74       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBRegressor(objective=\"binary:logistic\", random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred=xgb_model.predict(X_test)\n",
    "score1=classification_report(y_test,y_pred.round())\n",
    "print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfef5b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.30      0.42        71\n",
      "           1       0.80      0.97      0.87       205\n",
      "\n",
      "    accuracy                           0.79       276\n",
      "   macro avg       0.77      0.63      0.65       276\n",
      "weighted avg       0.79      0.79      0.76       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimator_list = [\n",
    "        (\"knn\", KNeighborsClassifier()),\n",
    "        (\"svm_rbf\", SVC()),\n",
    "        (\"dt\", DecisionTreeClassifier()),\n",
    "        (\"rf\", RandomForestClassifier()),\n",
    "        (\"mlp\", MLPClassifier(alpha=1, max_iter=1000)),\n",
    "    ]\n",
    "stack_model = StackingClassifier(\n",
    "        estimators=estimator_list, final_estimator=LogisticRegression()\n",
    "    )\n",
    "stack_model.fit(X_train, y_train)\n",
    "y_pred = stack_model.predict(X_test)\n",
    "score = classification_report(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca32eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
